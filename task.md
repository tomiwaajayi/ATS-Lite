# ATS Challenge â€” â€œWatch the ATS Thinkâ€

*A mini coding exercise that shows off frontâ€‘end polish, backâ€‘end logic, and a transparent agent loop.*

## 1 Â· Scenario

You ship a tiny **Next.js** site that:

1. **Preâ€‘loads a CSV** â€” `candidates.csv` (â‰ˆâ€¯50 dummy rows)

   ```csv
   id,full_name,title,location,years_experience,skills,availability_weeks,willing_to_relocate,etc.
   ```

2. Displays a **chat box** for recruiters to type naturalâ€‘language queries such as:

   > Backend engineers in Germany, most experience first.

3. Runs an explicit **MCP loop** (Think â†’ Act â†’ Act â†’ Speak) to

   * **filter** the dataset
   * **rank** the subset
   * **stream every step** to the UI with smooth animations

The assistant is nickâ€‘named **ATSâ€‘Lite**.

## 2 Â· Required Tools (pure JavaScript)

| Tool                        | Signature                                         | Purpose                            |
| --------------------------- | ------------------------------------------------- | ---------------------------------- |
| `filterCandidates(plan)`    | `{ include?, exclude? } â†’ Candidate[]`            | Boolean / regex / â‰¥ filtering      |
| `rankCandidates(ids, plan)` | `{ primary, tie_breakers? } â†’ Candidate[]`        | Scores & sorts the filtered subset |
| `aggregateStats(ids)`[^1]   | `ids[] â†’ { count, avg_experience, top_skills[] }` | Quick stats for richer replies     |

All tools are *synchronous* â€“ no DB or external I/O.

[^1]: Optional, but helpful for richer assistant summaries.

## 3 Â· MCP Workflow

1. **THINK** â€“ The LLM receives the user message **plus** the CSV header row and replies *only* with JSON:

   ```json
   {
     "filter": { /* FilterPlan */ },
     "rank":   { /* RankingPlan */ }
   }
   ```

2. **ACTâ€¯1** â€“ Frontâ€‘end calls `filterCandidates(filterPlan)`

3. **ACTâ€¯2** â€“ Frontâ€‘end calls `rankCandidates(ids, rankingPlan)`

4. **SPEAK** â€“ Frontâ€‘end calls the LLM again, passing the **topâ€¯5 rows** to generate a recruiterâ€‘friendly summary

Each phase emits an event that surfaces live in the UI.

## 4 Â· UI & Animation Requirements

| Area                 | Mustâ€‘have                                                                                                                           | Library ideas                     |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------- | --------------------------------- |
| **Chat panel**       | Stream assistant tokens as they arrive                                                                                              | Tailwind, `react-virtual`         |
| **Timeline sidebar** | Collapsible panel that reveals, one line at a time: 1ï¸âƒ£ filter plan JSON â†’ 2ï¸âƒ£ match count â†’ 3ï¸âƒ£ ranking plan JSON â†’ 4ï¸âƒ£ ranked IDs | `framer-motion` (stagger / slide) |
| **Result table**     | Always shows the **current ranked subset**; when rows change or reorder, they **animate** into place                                | `framer-motion` layout / FLIP     |
| Loading cues         | Progress bar or shimmer while the agent works                                                                                       | `nprogress` or custom             |
| Row details          | Click a row â†’ side panel with full candidate JSON                                                                                   | â€”                                 |

## 5 Â· Example Flow

```text
You: Backend engineers in Germany, most experience first.

Timeline â–¶
1ï¸âƒ£ filter plan ready
2ï¸âƒ£ 7 rows matched
3ï¸âƒ£ ranking plan ready
4ï¸âƒ£ ranked IDs [14,â€¯5,â€¯22,â€¯â€¦]   â† lines fadeâ€‘in one by one

Result table slides into new order.

ATSâ€‘Lite: I found 7 matches (avgâ€¯6.1â€¯yrs). Here are the top threeâ€¦
```

## 6 Â· Deliverables

* **Git repo** with clean commits & a clear `README.md` (`pnpm install && pnpm dev`)
* **`.env.example`** for the OpenAI key
* **One Jest test**
  *Input:* *React dev, Cyprus, sort by experience desc*
  *Expectation:* candidate **#12** appears above **#5**
* **Links** â€” provide both (a) the GitHub repository URL and (b) a live deployment link (e.g., Vercel, Netlify)

## 7 Â· Evaluation Criteria

* **Agent transparency** â€“ each MCP phase surfaced in order
* **Prompt robustness** â€“ LLM reliably emits valid JSON; graceful retry on errors
* **Animation & UX** â€“ timeline staggers, rows reâ€‘flow without jank; keyboard shortcut (âŒ˜â€¯+â€¯Enter) to send
* **Code quality** â€“ modular data helpers, tidy state (Context/Zustand), minimal globals
* **Docs & tests** â€“ quick start, clear tool contracts, meaningful test coverage

---

### Keep It Small ğŸ“

No auth, no uploads, no database â€” just a CSV in memory, two synchronous tools, two LLM calls, and a polished UI that lets reviewers **watch the ATS think** in real time.
